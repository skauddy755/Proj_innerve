{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "skincancer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxfCfvXNqkb"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iny4DZoKnYxP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC1S8NT01v4S"
      },
      "source": [
        "!unzip -qq '/content/drive/MyDrive/isic-2019.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5TyIZyZKGbz"
      },
      "source": [
        "# ==== Install Dependencies\n",
        "\n",
        "!pip install -q efficientnet-pytorch\n",
        "!pip install -q albumentations\n",
        "!pip install -q pytorch_ranger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCkFVHBTKXJ0"
      },
      "source": [
        "# ==== Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "import albumentations as aug\n",
        "from albumentations.pytorch.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "from pytorch_ranger import Ranger\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX3Cb4RZDIyo"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdNEttTexy7_"
      },
      "source": [
        "#Data Loader and Model optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OpdNPwrxxtC"
      },
      "source": [
        "dataset    = Cloader(image_path,targets,resize=None,transforms=None)\r\n",
        "\"\"\" returns {'image':tensor_image,'targets':tensor_labels} \"\"\"\r\n",
        "dataloader = DataLoader(dataset,batch_size=64\r\n",
        "                                     ,shuffle=True,num_workers=4)\r\n",
        "                                     \r\n",
        "\"\"\" using next(iter(dataloader)) returns a dictionary with keys 'image'\r\n",
        " and 'targets'.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HThsTA1x6Mn"
      },
      "source": [
        "es = EarlyStop(patience=7, mode=\"max\", delta=0.0001) \r\n",
        "\r\n",
        "\"\"\" Sample code \"\"\"\r\n",
        "for epoch in range(epochs):\r\n",
        "    epoch_score = Trainer.evaluate(......)\r\n",
        "    es(epoch_score , model , model_path =\"./best.pth\")\r\n",
        "    \"\"\" model_path is the location+filename to save the best model \"\"\"\r\n",
        "    if es.early_stop=True:\r\n",
        "\t    break\r\n",
        "\r\n",
        "es.reset()  \"\"\" resets the best_epoch_score, if in case training multiple\r\n",
        "                folds without creating 'es' object again and again.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyMal3LVyUcP"
      },
      "source": [
        "trainer        = Trainer(model,optimizer,device,train_scheduler = None,\r\n",
        "                 val_scheduler = None,accumulation_steps=1,fp16=False,\r\n",
        "                use_mean_loss=False,checkpoint=None,save_path = \"./\")\r\n",
        "                \r\n",
        "\"\"\" Training and Evaluating \"\"\"\r\n",
        "train_loss              = trainer.train(train_dataloader)\r\n",
        "y_true ,y_pred,val_loss = trainer.evaluate(val_dataloader)\r\n",
        "\r\n",
        "\"\"\" Prediction \"\"\"\r\n",
        "y_preds                 = trainer.predict(test_dataloader)  \r\n",
        "\r\n",
        "\"\"\" In depths \"\"\"\r\n",
        "\"\"\" train_scheduler/val_scheduler : call scheduler.step() while training\r\n",
        "                                    or after validating\r\n",
        "    accumulation_step             : implements gradient accumulation \r\n",
        "                                    (default = 1)\r\n",
        "    fp16                          : mixed precision training\r\n",
        "    use_mean_loss                 : loss.mean().backward()\r\n",
        "                                    (false if loss is already meaned)\r\n",
        "    checkpoint                    : torch.load(checkpoint),loads the \r\n",
        "                                    checkpoint and resumes training.\r\n",
        "    save_path                     : location to save the last epoch \r\n",
        "                                    weights                             \"\"\"\r\n",
        "\r\n",
        "\"\"\" Having problem with non resumable training epochs? \"\"\"    \r\n",
        "trainer.saver()  \"\"\" saves the last epoch to the save_path location \"\"\"\r\n",
        "\r\n",
        "\"\"\" dataloader must be set in the same state to resume training \r\n",
        "Use [https://gist.github.com/usamec/1b3b4dcbafad2d58faa71a9633eea6a5]\r\n",
        "an implementation of ResumableRandomSampler()  \"\"\"\r\n",
        "\r\n",
        "sampler = ResumableRandomSampler(dataset)\r\n",
        "loader  = DataLoader(dataset, batch_size=64, sampler=sampler)\r\n",
        "torch.save(sampler.get_state(), \"test_samp.pth\") -- save the state\r\n",
        "sampler.set_state(torch.load(\"test_samp.pth\"))  -- load and set the state\r\n",
        "\r\n",
        "\"\"\" and tadaa , resume training 100 % :) \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE2_D3jkyYaG"
      },
      "source": [
        "logger   = Logger(path=\"./\")  \"\"\" save path for logger\"\"\"\r\n",
        "logger.write( message ,verbose = 1) \"\"\" verbose to print the message\"\"\"\r\n",
        "\r\n",
        "\"\"\" Helps Keep Track of Training \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC8m4ERhya8Z"
      },
      "source": [
        "saver    = Saver(path=\"./\" , mode = \"max\")\r\n",
        "\"\"\" saves the model, optimizer and scheduler based on score and mode \"\"\"\r\n",
        "\r\n",
        "saver.save(model,optimizer,scheduler,metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RGV9XKvyeFc"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.base_model = timm.create_model('resnet18',pretrained=True,num_classes=1)\r\n",
        "    def forward(self, image, targets):\r\n",
        "        batch_size, _, _, _ = image.shape\r\n",
        "        out = self.base_model(image)\r\n",
        "        loss = nn.BCEWithLogitsLoss()(out.view(batch_size,), targets.type_as(out))\r\n",
        "        return out, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2tX1Of8HUIf"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6XaraMVQxHL"
      },
      "source": [
        "df = pd.read_csv('/content/ISIC_2019_Training_GroundTruth.csv')\n",
        "df['label'] = np.argmax(np.array(df.drop(['image'],axis=1)),axis=1)\n",
        "classes = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC'] \n",
        "\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWufKb0kmjKz"
      },
      "source": [
        "np.sum(df.label.values==4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn9yAD3Ed0md"
      },
      "source": [
        "wb = np.array([4522,12875,3323,867,2624,239,253,628])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DScQa8CQmx_b"
      },
      "source": [
        "p = (wb.sum()-wb)/wb.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc_weQvHPCj0"
      },
      "source": [
        "def softmax(array):\n",
        "    return np.exp(array)/np.sum(np.exp(array),axis=1).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHDWzb_2kXmT"
      },
      "source": [
        "np.exp(p)/(np.sum(np.exp(p)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EuwERXqIpbE"
      },
      "source": [
        "# print(df['MEL'].value_counts())\n",
        "# print(df['NV'].value_counts())\n",
        "# print(df['BCC'].value_counts())\n",
        "# print(df['AK'].value_counts())\n",
        "# print(df['BKL'].value_counts())\n",
        "# print(df['DF'].value_counts())\n",
        "# print(df['VASC'].value_counts())\n",
        "# print(df['SCC'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpje_XSoNzse"
      },
      "source": [
        "save_root = \"/content/drive/MyDrive/ACMCancer/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOIEEnXKOXDe"
      },
      "source": [
        "training_data_path = \"/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n",
        "\n",
        "# X_train , X_val ,Y_train , Y_val = tts(df, df.label.values, test_size=0.20\n",
        "#                                        ,random_state=42,stratify=df.label.values)\n",
        "# X_train       = X_train.reset_index(drop=True)\n",
        "# X_val         = X_val.reset_index(drop=True)\n",
        "\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/ACMCancer/train.csv')\n",
        "X_val   = pd.read_csv('/content/drive/MyDrive/ACMCancer/val.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2Ua3O5fOW-I"
      },
      "source": [
        "# ===== Augmentations\n",
        "\n",
        "image_size=224\n",
        "transforms_train = aug.Compose([\n",
        "    aug.Resize(image_size, image_size),\n",
        "    # aug.Transpose(p=0.5),\n",
        "    aug.VerticalFlip(p=0.5),\n",
        "    aug.HorizontalFlip(p=0.5),\n",
        "    aug.RandomBrightness(limit=0.2, p=0.75),\n",
        "    aug.RandomContrast(limit=0.2, p=0.75),\n",
        "    # aug.OneOf([\n",
        "    #     aug.MotionBlur(blur_limit=5),\n",
        "    #     aug.MedianBlur(blur_limit=5),\n",
        "    #     # aug.GaussianBlur(blur_limit=5),\n",
        "    #     aug.GaussNoise(var_limit=(5.0, 30.0)),\n",
        "    # ], p=0.7),\n",
        "\n",
        "    aug.OneOf([\n",
        "        aug.OpticalDistortion(distort_limit=1.0),\n",
        "        aug.GridDistortion(num_steps=5, distort_limit=1.),\n",
        "        aug.ElasticTransform(alpha=3),\n",
        "    ], p=0.7),\n",
        "\n",
        "    aug.CLAHE(clip_limit=4.0, p=0.7),\n",
        "    aug.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
        "    aug.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
        "    aug.Cutout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.5),    \n",
        "    aug.Normalize()\n",
        "])\n",
        "\n",
        "transforms_val = aug.Compose([\n",
        "    aug.Resize(image_size, image_size),\n",
        "    aug.Normalize()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8a9-n4juW05"
      },
      "source": [
        "# !pip install -U git+https://github.com/ildoonet/cutmix\n",
        "# from cutmix.cutmix import CutMix\n",
        "# from cutmix.utils import CutMixCrossEntropyLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvu4IaecOW6a"
      },
      "source": [
        "train_images     = X_train.image.values.tolist()\n",
        "train_images     = [os.path.join(training_data_path, i+\".jpg\") for i in train_images]\n",
        "\n",
        "test_images      = X_val.image.values.tolist()\n",
        "test_images      = [os.path.join(training_data_path, i+\".jpg\") for i in test_images]\n",
        "\n",
        "train_dataset    = Cloader(train_images,X_train.label.values,None,transforms_train)\n",
        "#train_dataset    = CutMix(train_dataset, num_class=5, beta=1.0, prob=0.5, num_mix=3)\n",
        "test_dataset     = Cloader(test_images,X_val.label.values,None,transforms_val)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True,num_workers=2)\n",
        "val_dataloader   = DataLoader(test_dataset,batch_size=32,shuffle=False,num_workers=2)\n",
        "\n",
        "device           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EkzwBWrPCmN"
      },
      "source": [
        "# ===== Define model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.base_model = EfficientNet.from_pretrained('efficientnet-b0',num_classes=8)\n",
        "    def forward(self, image, targets):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "        out = self.base_model(image)\n",
        "        targets = torch.tensor(targets,dtype=torch.int64)\n",
        "        weights = torch.tensor([0.11717086, 0.08425763, 0.12285029, 0.13535795, 0.12628751,0.13875566, 0.13867899, 0.13664111])\n",
        "        loss = nn.CrossEntropyLoss(weight=weights.cuda())(out.view(batch_size,8), targets)\n",
        "        return out, loss\n",
        "\n",
        "model = Net()\n",
        "model.to(device);\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/ACMCancer/best17decagain.pth\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcSuSfGXPChd"
      },
      "source": [
        "optimizer = Ranger(model.parameters(),lr=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer,factor=0.8, mode=\"min\", patience=2)\n",
        "\n",
        "trainer   = Trainer(model=model,optimizer=optimizer,device=device,val_scheduler=scheduler)\n",
        "logger    = Logger()\n",
        "\n",
        "es        = EarlyStop(patience=5,mode=\"min\") # mode = min to minimise loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWmkwlMMPCRE"
      },
      "source": [
        "epochs = 30\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    logger.write(f\"+ ===== Epoch {epoch+1}/{epochs} ===== +\")\n",
        "    train_loss              = trainer.train(train_dataloader)\n",
        "    y_true,y_pred ,val_loss = trainer.evaluate(val_dataloader)\n",
        "    y_pred                  = softmax(y_pred)\n",
        "    accuracy                = accuracy_score(y_true,np.argmax(y_pred,axis=1))\n",
        "    es(val_loss,model,model_path =\"/content/drive/MyDrive/ACMCancer/best17dec_again.pth\")\n",
        "    logger.write(f\"train_loss {train_loss} val_loss {val_loss} \")\n",
        "    logger.write(f\"val accuracy_score {accuracy} \")\n",
        "    logger.write(\" \")\n",
        "    if es.early_stop:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sae-YQnTY_De"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQrvw74qY_A6"
      },
      "source": [
        "es        = EarlyStop(patience=7,mode=\"min\")\n",
        "optimizer = Ranger(model.parameters(),lr=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer,factor=0.6, mode=\"min\", patience=2)\n",
        "\n",
        "trainer   = Trainer(model=model,optimizer=optimizer,device=device,val_scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP4gfG2kY--l"
      },
      "source": [
        "epochs = 30\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    logger.write(f\"+ ===== Epoch {epoch+1}/{epochs} ===== +\")\n",
        "    train_loss              = trainer.train(train_dataloader)\n",
        "    y_true,y_pred ,val_loss = trainer.evaluate(val_dataloader)\n",
        "    y_pred                  = softmax(y_pred)\n",
        "    accuracy                = accuracy_score(y_true,np.argmax(y_pred,axis=1))\n",
        "    es(val_loss,model,model_path =\"/content/drive/MyDrive/ACMCancer/best17decagain.pth\")\n",
        "    logger.write(f\"train_loss {train_loss} val_loss {val_loss} \")\n",
        "    logger.write(f\"val accuracy_score {accuracy} \")\n",
        "    logger.write(\" \")\n",
        "    if es.early_stop:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM-dU3pLY-7p"
      },
      "source": [
        "epochs = 30\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    logger.write(f\"+ ===== Epoch {epoch+1}/{epochs} ===== +\")\n",
        "    train_loss              = trainer.train(train_dataloader)\n",
        "    y_true,y_pred ,val_loss = trainer.evaluate(val_dataloader)\n",
        "    y_pred                  = softmax(y_pred)\n",
        "    accuracy                = accuracy_score(y_true,np.argmax(y_pred,axis=1))\n",
        "    es(val_loss,model,model_path =\"/content/drive/MyDrive/ACMCancer/best17decagain2.pth\")\n",
        "    logger.write(f\"train_loss {train_loss} val_loss {val_loss} \")\n",
        "    logger.write(f\"val accuracy_score {accuracy} \")\n",
        "    logger.write(\" \")\n",
        "    if es.early_stop:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lseH-piXY-35"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW9JVZtF7LMK"
      },
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/ACMCancer/best17decagain.pth\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrinSERi7LIn"
      },
      "source": [
        "torch.save(model.base_model.cpu(),'/content/drive/MyDrive/ACMCancer/canc.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58trLFL47LFw"
      },
      "source": [
        "model.base_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOji7SM37LCy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRC5ljBD9bgc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqOzWW2d9bbB"
      },
      "source": [
        "# train_dataset    = Cloader(train_images,X_train.label.values,None,transforms_train)\n",
        "#train_dataset    = CutMix(train_dataset, num_class=5, beta=1.0, prob=0.5, num_mix=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9ghQaEm9bYW"
      },
      "source": [
        "cls0=['ISIC_0032586', 'ISIC_0058999', 'ISIC_0071132', 'ISIC_0063369',\n",
        "       'ISIC_0063732', 'ISIC_0070516', 'ISIC_0026811', 'ISIC_0032736',\n",
        "       'ISIC_0032447']\n",
        "\n",
        "cls1=['ISIC_0055906', 'ISIC_0058529', 'ISIC_0030688',\n",
        "       'ISIC_0061304', 'ISIC_0024934', 'ISIC_0056288']\n",
        "\n",
        "cls2=['ISIC_0056157', 'ISIC_0069185', 'ISIC_0029129', 'ISIC_0058984',\n",
        "       'ISIC_0068505', 'ISIC_0058310', 'ISIC_0071757', 'ISIC_0072638',\n",
        "       'ISIC_0058039', 'ISIC_0067819', 'ISIC_0063572']\n",
        "\n",
        "cls3 = ['ISIC_0067755', 'ISIC_0060814', 'ISIC_0071417', 'ISIC_0071605',\n",
        "       'ISIC_0070507', 'ISIC_0053688', 'ISIC_0069027', 'ISIC_0064638',\n",
        "       'ISIC_0059108', 'ISIC_0056643', 'ISIC_0057387']\n",
        "\n",
        "cls4 = ['ISIC_0031061', 'ISIC_0026276', 'ISIC_0071344',\n",
        "       'ISIC_0012854_downsampled', 'ISIC_0025297', 'ISIC_0059055',\n",
        "       'ISIC_0063201', 'ISIC_0053750', 'ISIC_0033758', 'ISIC_0054965',\n",
        "       'ISIC_0012955_downsampled', 'ISIC_0029102', 'ISIC_0025510']\n",
        "\n",
        "cls5 = ['ISIC_0060327', 'ISIC_0069653', 'ISIC_0025594', 'ISIC_0053519',\n",
        "       'ISIC_0060024', 'ISIC_0029824', 'ISIC_0061232', 'ISIC_0063831',\n",
        "       'ISIC_0063605', 'ISIC_0067025', 'ISIC_0025223']\n",
        "\n",
        "cls6 = ['ISIC_0065784', 'ISIC_0028188', 'ISIC_0027256', 'ISIC_0033844',\n",
        "       'ISIC_0031996', 'ISIC_0070113', 'ISIC_0025924', 'ISIC_0033230',\n",
        "       'ISIC_0032057', 'ISIC_0057994', 'ISIC_0026393', 'ISIC_0033969',\n",
        "       'ISIC_0030722', 'ISIC_0031217', 'ISIC_0055650']\n",
        "\n",
        "cls7 = ['ISIC_0056522', 'ISIC_0026466', 'ISIC_0033084', 'ISIC_0061988',\n",
        "       'ISIC_0024843', 'ISIC_0059953', 'ISIC_0030991', 'ISIC_0055107',\n",
        "       'ISIC_0025577', 'ISIC_0068997', 'ISIC_0063275', 'ISIC_0030821',\n",
        "       'ISIC_0025831', 'ISIC_0057224', 'ISIC_0068229', 'ISIC_0032173',\n",
        "       'ISIC_0029067', 'ISIC_0060333', 'ISIC_0029549', 'ISIC_0061451',\n",
        "       'ISIC_0057610', 'ISIC_0068938', 'ISIC_0029362']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwbmRSed_nsw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqI9WjgL_nol"
      },
      "source": [
        "\n",
        "test_dataset     = Cloader(test_images,0,None,transforms_val)\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True,num_workers=2)\n",
        "val_dataloader   = DataLoader(test_dataset,batch_size=1,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4_29d0k_nlc"
      },
      "source": [
        "image = next(iter(val_dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUGx48abARCI"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGzDfyV_9bSC"
      },
      "source": [
        "img ='ISIC_0063369'\n",
        "test_images = os.path.join(training_data_path,img +\".jpg\")\n",
        "image = Image.open(test_images)\n",
        "image = np.array(image)\n",
        "augmented = transforms_val(image=image)\n",
        "image = augmented[\"image\"]\n",
        "image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "image = torch.tensor([image], dtype=torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT_Pxmjr_cC7"
      },
      "source": [
        "model.base_model(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qASeAOzv_cBH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeKpdEpt_b91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWTHpLb5_b6_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSQo_5CFTgbq"
      },
      "source": [
        "torch.save(model.state_dict(),\"/content/drive/MyDrive/ACMCancer/last.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXCd7rKhTp38"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gB8fIAS31zN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}